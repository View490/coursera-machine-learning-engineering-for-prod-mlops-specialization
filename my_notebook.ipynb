{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Course 1 - Introduction to Machine Learning in Production"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview of ML Lifecycle and Deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Beyond Notebook: Production ML isn't just a notebook, it's a hybrid.\n",
        "* Dual Expertise: ML teams need both ML and software engineering knowledges for building and deploying.\n",
        "* Product not Project: Not on creating a model, there are need for CI/CD model development.\n",
        "* Model Potential: To maximize the values of ML project, it nee to be how to deploy in production."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deployment Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Scenarios:\n",
        "* Camera take pictures of smartphones on a production line.\n",
        "* An API call sends the image to a prediction server (cloud or edge based)\n",
        "* The server analyzed images if phone is defective.\n",
        "\n",
        "Deployment Challenges:\n",
        "* More than ML Code: Need software to handle API calls, control decisions, and handle production specifics.\n",
        "* Edge vs Cloud: depend on factors ex. internet reliability, latency, and etc.\n",
        "* Real-World Surprises: Factory condition might differ from training environment, cuase issue called concept drift (e.g., dark lighting)\n",
        "* Bridging the Gap: Method to translate smoothly to production deployment by a little adaptating such as shadow deployment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Steps of ML Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Scope the Seas: define the goal of proeject, what is input and output and why we have to use ML model ?\n",
        "2. Gather Treasure: Stock up on valuable data, baseline, label, and organize it. Create a map that navigatable from the model.\n",
        "3. Train the Model: build, train, select, analyze errors of the models.\n",
        "4. Iterate and Explore: Back to data, model update, chcek project scoping.\n",
        "5. Pre-Deployment Check: makesure the model is suitable for deploying environment.\n",
        "6. Deploy: start deploy model in production by defined method.\n",
        "7. Monitoring and Matain: to avoid any huge error effect, monitoring such as logs and losses are great for avoid error.\n",
        "8. Refine: checks the CI/CD pipeline, concept drift, data distribution and wether or not the model still suit for business goal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example - Speech Recognition\n",
        "\n",
        "**Scoping Stage**\n",
        "\n",
        "**Data Stage**\n",
        "\n",
        "**Modeling Stage**\n",
        "\n",
        "**Deployment Stage**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select and Train a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Selecting and Training a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Error Analysis and Performance Auditing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Definition and Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Data and Establish Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Label and Organize Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scoping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Laboratories***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***LAB1 - A Journal to Data***\n",
        "\n",
        "Objective and Methodology:\n",
        "* Experience the Data-Centric Model issues, diagnosis tools, and how to solve problems.\n",
        "* ***ISSUE :*** Data Imbalance, Accuracy_Score, Overfitting.\n",
        "* ***SOLUTIONS :*** Data Augmentaion, Balanced_Accuracy_Score.\n",
        "* ***CONSIDERATION :*** Same model with various kind of dataset.\n",
        "\n",
        ">Topics1: Imbalance Dataset\n",
        "* cause by data storage damages. The lossed data cause imbalance data issue.\n",
        "* imbalance data: is when some labels data has much more samples than other.\n",
        "* result: accuracy metric is misleading provides a false sense of model performance.\n",
        "* solve: use balanced_accuracy_score to see the see the average accuracy across labels.\n",
        "\n",
        ">Topics2: Training with Complete Daaset.\n",
        "* result: both accuracy and balanced_accuracy is close similar.\n",
        "* consideration: overfitting occur, from much difference in training and testing losses.\n",
        "\n",
        ">Topic3: Training with Data Augmentation\n",
        "* goal: increase data samples to solve imbalanece problem.\n",
        "* methods: img rotates, resizes, crops, filps.\n",
        "* ***warning :*** data augmentation must use in training dataset only.\n",
        "* result: better balanced_accuracy_score than imbalance dataset. Solved overfitting problem.\n",
        "\n",
        "Important Libraries:\n",
        "* tensorflow ImageDataGenerator: \\t create exmaple generator, and img augmentation.\n",
        "* tensorflow keras: create sequential model\n",
        "* skelarn metrics: model performance validation\n",
        "* os: file directory\n",
        "* pandas, numpy, matplotlib, seaborn: data visualizataion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***LAB2 - Data Labeling***\n",
        "\n",
        "Objectives and Methodologies:\n",
        "* Compare effects of ***Labeling Strategies*** on model performance.\n",
        "* Labeling Strategy including\n",
        "   * Randomly Generated Labels (performance lower bound).\n",
        "   * Automatic Generated Labels Based on Three Different Label Strategies.\n",
        "   * True Labels (performance upper bound).\n",
        "\n",
        "> Random Labeling.\n",
        "* normal distribution random number labels\n",
        "* ***RESULTS:*** accuracy = 50%\n",
        "\n",
        "> True Labels Values.\n",
        "* true labels expected to get highest performance.\n",
        "* ***RESULTS:*** accuracy = 91%\n",
        "\n",
        "> Automatic Labeling.\n",
        "\n",
        "* Defined Rules.(one labeling)\n",
        "   * defines dict of words that will be labeld as spam.\n",
        "   * not enough human define rules, comparing proportion with true labeled values.\n",
        "   * ***RESULTS:*** accuracy = 52%\n",
        "\n",
        "* Defined Better Rules.(two labeling)\n",
        "   * defines more dict of words that will be labeld as spam.\n",
        "   * defined dict of words that will be labels as NOT_spam.\n",
        "   * got higher datapoint (proportion of labeling and true-labeling.)\n",
        "   * ***RESULTS:*** accuracy = 70%\n",
        "\n",
        "* Defines More Rules.(included length rule)\n",
        "   * add length of words to rules of labeling.\n",
        "   * visualize the words legnth distribution to select parameter.\n",
        "   * ***RESULTS:*** accuracy = 86%\n",
        "\n",
        "Important Libraries:\n",
        "* sklearn metrics: accuracy score\n",
        "* sklearn naive_bayes: classifier\n",
        "* matplotlib, pandas: dataframe and labels visualization\n",
        "* sklearn extraction.text: vectorizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Course 2 - Machine Learning Data Lifecycle in Production"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Collecting, Labeling and Validation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Introduction to Machine Learning in ML Pipeline and MLEP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Collecting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Labeling Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validating Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering, Transformation and Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Transformation at Scale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Journey and Data Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Introduction to ML Metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evolving Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Enterprise Data Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Labeling, Augmentation and Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Advanced Labeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing Different Data Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Laboratories***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LAB3 - Tensorflow Data Validation\n",
        "\n",
        "Objectives and Methodlogoies:\n",
        "* practice of TFDV from Tensorflow Extended (TFX)\n",
        "* TFDV provides insight of data analysis process including:\n",
        "   * baseline statistics.\n",
        "   * schema.\n",
        "   * serving data validation.\n",
        "   * find and fix data anomalies.\n",
        "\n",
        "> Generate Statisitcs and Schema.\n",
        "* Import Dataset.\n",
        "* train_df.\n",
        "   * add_extra_row, to create anomalies sample.\n",
        "   * generate train_stats.\n",
        "   * visualize train_stats.\n",
        "   * infer schema.\n",
        "   * display schema.\n",
        "* eval_df.\n",
        "   * generate eval_stats.\n",
        "   * visualize eval_stats args comparing to train_stats.\n",
        "   * filter out unnessesary values both train_df, eval_df.\n",
        "   * generate eval_stats and display both again.\n",
        "* validate_statistic by eval_stats and schema.\n",
        "* display it.\n",
        "\n",
        "> Revise Schema - to expand the anomalies thresholds.\n",
        "   * get_feature from schema.\n",
        "      * set new distribution_constrains.\n",
        "   * get_domain from schema.\n",
        "      * append domain values.\n",
        "   * set_domain numerical features.\n",
        "      * set feature range by schema_pb2.IntDomain\n",
        "* diplay validate_staistic, should be 'No anaomalies founded.\n",
        "\n",
        "> Examining Dataset Slices.\n",
        "* set slice_fn >>> slicing features.\n",
        "* pass schema and slice_fn to Statsoptions.\n",
        "* convert df to csv format (slicing support).\n",
        "* create sliced_stats from csv with args stats_option=StatOptions\n",
        "* use sliced_stats to generate and visualize_statistics\n",
        "* analyze the distribution of features on the selected slices.\n",
        "\n",
        "Important Libraries:\n",
        "* tensorflow: framework\n",
        "* tensorflow_data_validation: validate dataset.\n",
        "* tensorflow_metadata.proto.v0 : metadata and schema building.\n",
        "* tdfv utils slicing_util: get features for examining.\n",
        "* sklearn model_selection: data splitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LAB4 - Data Validation (Assignment)\n",
        "1. Setup and Imports.\n",
        "    * directory, tf, tfdv, tfdv slicing, tf metadata.\n",
        "2. Load Dataset.\n",
        "    * pandas load dataset.\n",
        "    * splitting dataset to train_ eval, and serving dataset.\n",
        "3. Generate and Visualize Training Dataset.\n",
        "    * remove irrelevant features.\n",
        "    * Insttantiate StatsOptions with args feature_whitelist.\n",
        "    * train_stats from train_df, stats_options.\n",
        "    * visualzie train_stats.\n",
        "4. Infer Schema.\n",
        "    * create shema by infer_schema train_stats.\n",
        "    * display schema.\n",
        "5. Calcualte, Visualize and Fix Evaluation Anomalies.\n",
        "    * generate eval_stats.\n",
        "    * compare train_stats and eval_stats by visualize stats (set lhs_stats and rhs_stats).\n",
        "    * detect anomalies by display the validate_statistics of eval_stats and schema (define this function as cal_anomalies).\n",
        "    * fix evaluation anomalies schema by:\n",
        "        * get_domain features from schema.\n",
        "        * append new unique values.\n",
        "        * cal_anomalies, this should no anomalies found.\n",
        "6. Schema Environments.\n",
        "    * check anomalies in serving env by define new options.\n",
        "    * serving_stats from serving_df, options.\n",
        "    * cal_anomalies.\n",
        "    * relax the distribition of features.\n",
        "        *serving has anomalies <1%, then we set distribution_constraints.min_domain_mass=0.9 on anomalies features.\n",
        "        * cal_anomalies, still found anomalies on domain features.\n",
        "    * modify schema.\n",
        "        * many domain has same set of values [a,b,c,d] but the anomalies <1% has only [a] on train_stats and [a,b] on serving_stats that cause anaomalies. ['metfomin']\n",
        "        * set_domain for all features ['metfomin_a1'],['metfomin_2'], etc, that has same set of values to same domain.\n",
        "        * this will result in no anomalies founded since it detech for all values in same domain.\n",
        "        * print the domain value, will result in same set of values.\n",
        "    * anomalies detect with environments\n",
        "        * append default env to schema ('TRAINING', 'SERVING').\n",
        "        * exclude target_column (label) on SERVING env schema.\n",
        "        * cal_anomalies, should no anomalies found even no target col in serving_stats.\n",
        "7. Check for Data Dift and Skew.\n",
        "    * set skew_comparator and dift_comparator that expressed in L-infinity distance based on domain knowledges.\n",
        "    * create skew_drift_anomalies from validate_statistics by train_stats, schema, eval_stats, serving_stats (any stats we want).\n",
        "    * if not too much drift and skew in anay features we can ignore, but be consider because it can impact on model performance.\n",
        "8. Display Stats for Data Slices.\n",
        "    * get slice_fn by select feaures.\n",
        "    * generate stats for sliced dataset.\n",
        "    * display generated sliced data stats at specifified index (feature value).\n",
        "9. Freeze Schema.\n",
        "    * after schema was reviewed, then freeze schema.\n",
        "    * use tf io utils and TFDV write_schema_text()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LAB5 - Simple Feature Engineering\n",
        "\n",
        "Objectives and Methodologies:\n",
        "* use Tensorflow Transform to know under the hood of TFX Transform.\n",
        "* collect data, define metadata, create a preprocessing function, generate a constant graph with required transformations.\n",
        "\n",
        "> Define metadata.\n",
        "* define schema as  a dataset_Metadata object containing schema protobuf of dict mapping keys to features spec type.\n",
        "* display raw_data_metadata.\n",
        "\n",
        "> Create a Preprocessing Function (most important for tf.transformer).\n",
        "* preprocessin_fn\n",
        "    * extrat columns to local variables.\n",
        "    * data transformation using tft.\n",
        "    * return all values.\n",
        "\n",
        "> Generate a Constant Graph with Required Transformations.\n",
        "* TF Transformation use Apache Beam for scalability and flexibility. With pipe (|) operator.\n",
        "* define pipeline using Apache Beam context.\n",
        "* Analyze and transform dataset using preprocessing_fn, raw_data, raw_data_metadata.\n",
        "* unpack transform_dataset into transformed_data, transformed_metadata.\n",
        "* display result by ***pprint.pformat(var)***\n",
        "\n",
        "> \n",
        "\n",
        "Important Libraries:\n",
        "* Tensorflow: framework\n",
        "* tensorflow transformer: preprocessing\n",
        "* tensorflow metadata: create schema_utils "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LAB6 - Feature Engineering Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LAB7 - Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LAB8 - Feature Engineering (Assignment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LABX - Feature Engineering with Wheather Data\n",
        "\n",
        "Objective and Methodology:\n",
        "* Explored and Visualize time series dataset and declared schema.\n",
        "* Transformed data with tf.Transform\n",
        "* Preparing training dataset with WINDOWS\n",
        "\n",
        "Important Libraries\n",
        "* Tensorflow transformer: tarnsform data, and declare window size.\n",
        "* apache-beam: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Course 3 - Machine Learning Modeling Pipelines in Production"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neural Architecture Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameters Tuning: Searching for Best Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AutoML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AutoML Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Resource Management Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quantization and Pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## High-Performance Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### High-Performance Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Knowledge Distillation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Analysis (TFMA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Analysis Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Advanced Mode Analysis and Debugging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Continuous Evaluation and Monitoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpretability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explainable AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding Model Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Course 4 - Deploying Machine Learning Models in Production"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Serving Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Introduction to Model Serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Serving Infrastructure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensorflow Serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Serving Patterns and Infrastructure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Serving Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scaling Infrastructure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Online Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch Inference Scenarios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch Processing with ETL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Management and Delivery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ML Experience Management and Workflow Automation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MLOPs Methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Management and Deployment Infrastructure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Monitoring and Logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Monitoring and Logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Decay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GDPR and Privacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
