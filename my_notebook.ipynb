{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Course 1 - Introduction to Machine Learning in Production"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview of ML Lifecycle and Deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Beyond Notebook: Production ML isn't just a notebook, it's a hybrid.\n",
        "* Dual Expertise: ML teams need both ML and software engineering knowledges for building and deploying.\n",
        "* Product not Project: Not on creating a model, there are need for CI/CD model development.\n",
        "* Model Potential: To maximize the values of ML project, it nee to be how to deploy in production."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deployment Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Scenarios:\n",
        "* Camera take pictures of smartphones on a production line.\n",
        "* An API call sends the image to a prediction server (cloud or edge based)\n",
        "* The server analyzed images if phone is defective.\n",
        "\n",
        "Deployment Challenges:\n",
        "* More than ML Code: Need software to handle API calls, control decisions, and handle production specifics.\n",
        "* Edge vs Cloud: depend on factors ex. internet reliability, latency, and etc.\n",
        "* Real-World Surprises: Factory condition might differ from training environment, cuase issue called concept drift (e.g., dark lighting)\n",
        "* Bridging the Gap: Method to translate smoothly to production deployment by a little adaptating such as shadow deployment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Steps of ML Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Scope the Seas: define the goal of proeject, what is input and output and why we have to use ML model ?\n",
        "2. Gather Treasure: Stock up on valuable data, baseline, label, and organize it. Create a map that navigatable from the model.\n",
        "3. Train the Model: build, train, select, analyze errors of the models.\n",
        "4. Iterate and Explore: Back to data, model update, chcek project scoping.\n",
        "5. Pre-Deployment Check: makesure the model is suitable for deploying environment.\n",
        "6. Deploy: start deploy model in production by defined method.\n",
        "7. Monitoring and Matain: to avoid any huge error effect, monitoring such as logs and losses are great for avoid error.\n",
        "8. Refine: checks the CI/CD pipeline, concept drift, data distribution and wether or not the model still suit for business goal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example - Speech Recognition\n",
        "\n",
        "**Scoping Stage**\n",
        "\n",
        "**Data Stage**\n",
        "\n",
        "**Modeling Stage**\n",
        "\n",
        "**Deployment Stage**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select and Train a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Selecting and Training a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Error Analysis and Performance Auditing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Definition and Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Data and Establish Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Label and Organize Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scoping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Laboratories***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LAB WEEK1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***LAB1 - A Journal to Data***\n",
        "\n",
        "Objective and Methodology:\n",
        "* Experience the Data-Centric Model issues, diagnosis tools, and how to solve problems.\n",
        "* ***ISSUE :*** Data Imbalance, Accuracy_Score, Overfitting.\n",
        "* ***SOLUTIONS :*** Data Augmentaion, Balanced_Accuracy_Score.\n",
        "* ***CONSIDERATION :*** Same model with various kind of dataset.\n",
        "\n",
        ">Topics1: Imbalance Dataset\n",
        "* cause by data storage damages. The lossed data cause imbalance data issue.\n",
        "* imbalance data: is when some labels data has much more samples than other.\n",
        "* result: accuracy metric is misleading provides a false sense of model performance.\n",
        "* solve: use balanced_accuracy_score to see the see the average accuracy across labels.\n",
        "\n",
        ">Topics2: Training with Complete Daaset.\n",
        "* result: both accuracy and balanced_accuracy is close similar.\n",
        "* consideration: overfitting occur, from much difference in training and testing losses.\n",
        "\n",
        ">Topic3: Training with Data Augmentation\n",
        "* goal: increase data samples to solve imbalanece problem.\n",
        "* methods: img rotates, resizes, crops, filps.\n",
        "* ***warning :*** data augmentation must use in training dataset only.\n",
        "* result: better balanced_accuracy_score than imbalance dataset. Solved overfitting problem.\n",
        "\n",
        "Important Libraries:\n",
        "* tensorflow ImageDataGenerator: \\t create exmaple generator, and img augmentation.\n",
        "* tensorflow keras: create sequential model\n",
        "* skelarn metrics: model performance validation\n",
        "* os: file directory\n",
        "* pandas, numpy, matplotlib, seaborn: data visualizataion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LAB WEEK2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***LAB2 - Data Labeling***\n",
        "\n",
        "Objectives and Methodologies:\n",
        "* Compare effects of ***Labeling Strategies*** on model performance.\n",
        "* Labeling Strategy including\n",
        "   * Randomly Generated Labels (performance lower bound).\n",
        "   * Automatic Generated Labels Based on Three Different Label Strategies.\n",
        "   * True Labels (performance upper bound).\n",
        "\n",
        "> Random Labeling.\n",
        "* normal distribution random number labels\n",
        "* ***RESULTS:*** accuracy = 50%\n",
        "\n",
        "> True Labels Values.\n",
        "* true labels expected to get highest performance.\n",
        "* ***RESULTS:*** accuracy = 91%\n",
        "\n",
        "> Automatic Labeling.\n",
        "\n",
        "* Defined Rules.(one labeling)\n",
        "   * defines dict of words that will be labeld as spam.\n",
        "   * not enough human define rules, comparing proportion with true labeled values.\n",
        "   * ***RESULTS:*** accuracy = 52%\n",
        "\n",
        "* Defined Better Rules.(two labeling)\n",
        "   * defines more dict of words that will be labeld as spam.\n",
        "   * defined dict of words that will be labels as NOT_spam.\n",
        "   * got higher datapoint (proportion of labeling and true-labeling.)\n",
        "   * ***RESULTS:*** accuracy = 70%\n",
        "\n",
        "* Defines More Rules.(included length rule)\n",
        "   * add length of words to rules of labeling.\n",
        "   * visualize the words legnth distribution to select parameter.\n",
        "   * ***RESULTS:*** accuracy = 86%\n",
        "\n",
        "Important Libraries:\n",
        "* sklearn metrics: accuracy score\n",
        "* sklearn naive_bayes: classifier\n",
        "* matplotlib, pandas: dataframe and labels visualization\n",
        "* sklearn extraction.text: vectorizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Course 2 - Machine Learning Data Lifecycle in Production"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Collecting, Labeling and Validation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Introduction to Machine Learning in ML Pipeline and MLEP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Collecting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Labeling Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validating Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering, Transformation and Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Transformation at Scale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Journey and Data Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Introduction to ML Metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evolving Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Enterprise Data Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Labeling, Augmentation and Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Advanced Labeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing Different Data Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Laboratories***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LAB WEEK1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***LAB3 - Tensorflow Data Validation***\n",
        "\n",
        "Objectives and Methodlogoies:\n",
        "* practice of TFDV from Tensorflow Extended (TFX)\n",
        "* TFDV provides insight of data analysis process including:\n",
        "   * baseline statistics.\n",
        "   * schema.\n",
        "   * serving data validation.\n",
        "   * find and fix data anomalies.\n",
        "\n",
        "> Generate Statisitcs and Schema.\n",
        "* Import Dataset.\n",
        "* train_df.\n",
        "   * add_extra_row, to create anomalies sample.\n",
        "   * generate train_stats.\n",
        "   * visualize train_stats.\n",
        "   * infer schema.\n",
        "   * display schema.\n",
        "* eval_df.\n",
        "   * generate eval_stats.\n",
        "   * visualize eval_stats args comparing to train_stats.\n",
        "   * filter out unnessesary values both train_df, eval_df.\n",
        "   * generate eval_stats and display both again.\n",
        "* validate_statistic by eval_stats and schema.\n",
        "* display it.\n",
        "\n",
        "> Revise Schema - to expand the anomalies thresholds.\n",
        "   * get_feature from schema.\n",
        "      * set new distribution_constrains.\n",
        "   * get_domain from schema.\n",
        "      * append domain values.\n",
        "   * set_domain numerical features.\n",
        "      * set feature range by schema_pb2.IntDomain\n",
        "* diplay validate_staistic, should be 'No anaomalies founded.\n",
        "\n",
        "> Examining Dataset Slices.\n",
        "* set slice_fn >>> slicing features.\n",
        "* pass schema and slice_fn to Statsoptions.\n",
        "* convert df to csv format (slicing support).\n",
        "* create sliced_stats from csv with args stats_option=StatOptions\n",
        "* use sliced_stats to generate and visualize_statistics\n",
        "* analyze the distribution of features on the selected slices.\n",
        "\n",
        "Important Libraries:\n",
        "* tensorflow: framework\n",
        "* tensorflow_data_validation: validate dataset.\n",
        "* tensorflow_metadata.proto.v0 : metadata and schema building.\n",
        "* tdfv utils slicing_util: get features for examining.\n",
        "* sklearn model_selection: data splitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***LAB4 - Data Validation (Assignment)***\n",
        "1. Setup and Imports.\n",
        "    * directory, tf, tfdv, tfdv slicing, tf metadata.\n",
        "2. Load Dataset.\n",
        "    * pandas load dataset.\n",
        "    * splitting dataset to train_ eval, and serving dataset.\n",
        "3. Generate and Visualize Training Dataset.\n",
        "    * remove irrelevant features.\n",
        "    * Insttantiate StatsOptions with args feature_whitelist.\n",
        "    * train_stats from train_df, stats_options.\n",
        "    * visualzie train_stats.\n",
        "4. Infer Schema.\n",
        "    * create shema by infer_schema train_stats.\n",
        "    * display schema.\n",
        "5. Calcualte, Visualize and Fix Evaluation Anomalies.\n",
        "    * generate eval_stats.\n",
        "    * compare train_stats and eval_stats by visualize stats (set lhs_stats and rhs_stats).\n",
        "    * detect anomalies by display the validate_statistics of eval_stats and schema (define this function as cal_anomalies).\n",
        "    * fix evaluation anomalies schema by:\n",
        "        * get_domain features from schema.\n",
        "        * append new unique values.\n",
        "        * cal_anomalies, this should no anomalies found.\n",
        "6. Schema Environments.\n",
        "    * check anomalies in serving env by define new options.\n",
        "    * serving_stats from serving_df, options.\n",
        "    * cal_anomalies.\n",
        "    * relax the distribition of features.\n",
        "        *serving has anomalies <1%, then we set distribution_constraints.min_domain_mass=0.9 on anomalies features.\n",
        "        * cal_anomalies, still found anomalies on domain features.\n",
        "    * modify schema.\n",
        "        * many domain has same set of values [a,b,c,d] but the anomalies <1% has only [a] on train_stats and [a,b] on serving_stats that cause anaomalies. ['metfomin']\n",
        "        * set_domain for all features ['metfomin_a1'],['metfomin_2'], etc, that has same set of values to same domain.\n",
        "        * this will result in no anomalies founded since it detech for all values in same domain.\n",
        "        * print the domain value, will result in same set of values.\n",
        "    * anomalies detect with environments\n",
        "        * append default env to schema ('TRAINING', 'SERVING').\n",
        "        * exclude target_column (label) on SERVING env schema.\n",
        "        * cal_anomalies, should no anomalies found even no target col in serving_stats.\n",
        "7. Check for Data Dift and Skew.\n",
        "    * set skew_comparator and dift_comparator that expressed in L-infinity distance based on domain knowledges.\n",
        "    * create skew_drift_anomalies from validate_statistics by train_stats, schema, eval_stats, serving_stats (any stats we want).\n",
        "    * if not too much drift and skew in anay features we can ignore, but be consider because it can impact on model performance.\n",
        "8. Display Stats for Data Slices.\n",
        "    * get slice_fn by select feaures.\n",
        "    * generate stats for sliced dataset.\n",
        "    * display generated sliced data stats at specifified index (feature value).\n",
        "9. Freeze Schema.\n",
        "    * after schema was reviewed, then freeze schema.\n",
        "    * use tf io utils and TFDV write_schema_text()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LAB WEEK2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***LAB5 - Simple Feature Engineering***\n",
        "\n",
        "Objectives and Methodologies:\n",
        "* use Tensorflow Transform to know under the hood of TFX Transform.\n",
        "* collect data, define metadata, create a preprocessing function, generate a constant graph with required transformations.\n",
        "\n",
        "> Define metadata.\n",
        "* define schema as  a dataset_Metadata object containing schema protobuf of dict mapping keys to features spec type.\n",
        "* display raw_data_metadata.\n",
        "\n",
        "> Create a Preprocessing Function (most important for tf.transformer).\n",
        "* preprocessin_fn\n",
        "    * extrat columns to local variables.\n",
        "    * data transformation using tft.\n",
        "    * return all values.\n",
        "\n",
        "> Generate a Constant Graph with Required Transformations.\n",
        "* TF Transformation use Apache Beam for scalability and flexibility. With pipe (|) operator.\n",
        "* define pipeline using Apache Beam context.\n",
        "* Analyze and transform dataset using preprocessing_fn, raw_data, raw_data_metadata.\n",
        "* unpack transform_dataset into transformed_data, transformed_metadata.\n",
        "* display result by ***pprint.pformat(var)***\n",
        "\n",
        "> \n",
        "\n",
        "Important Libraries:\n",
        "* Tensorflow: framework\n",
        "* tensorflow transformer: preprocessing\n",
        "* tensorflow metadata: create schema_utils "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***LAB6 - Feature Engineering Pipeline***\n",
        "\n",
        "Objectives and Methodlogies:\n",
        "* Explore machine learning pipeline from Tensorflow Transform.\n",
        "* Feature Extraction built by Tensorflow Extension, including:\n",
        "    * ingest data from a base directory with `ExampleGen`.\n",
        "    * compute training data statistics with `StatisticsGen`.\n",
        "    * anomalies detect in evaluation data with `ExampleValidation`.\n",
        "    * Preprocess data into suitable features with `Transform`.\n",
        "\n",
        "> Setup, Define, and Visualize Dataset.\n",
        "* Import important libraries.\n",
        "* Import tfx.orchestration.\n",
        "* define: `pipeline_root`, `data_root`, `data_filepath`.\n",
        "* display dataset (head, matplotlib, etc)\n",
        "\n",
        "> Create and Run the Interactive Context.\n",
        "* `context` initial interactivecontent with local sqlite file by `pipeline_root`.\n",
        "\n",
        "> ExampleGen.\n",
        "* `CsvExampleGen <<< _data_root`.\n",
        "* instantiate `ExampleGen` with input csv dataset.\n",
        "    * this split data into training and evaluation sets (default: 2:1).\n",
        "    * convert each row into `tf.train.Example` suitable for TFX component.\n",
        "* `context.run(example_gen)`\n",
        "* get artifact object from example_gen output. {splitname, uri}\n",
        "    * if vertify the artifact uri, will show the data saved in gz zip.\n",
        "* To examine examples of the data saved in `TFRecord` format:\n",
        "    1. get list of files in directory (all compressed TFRecord files).\n",
        "    2. create `TFRecordDataset` to read these files.\n",
        "\n",
        "> StatisticsGen.\n",
        "* `StatisticsGen <<< ExampleGen`.\n",
        "* this `StatisticsGen` component use TFDV under the hood.\n",
        "* we can show statistics output by `context.show(...)`.\n",
        "* same as previous lab, statisticsGen record all statistics values.\n",
        "\n",
        "> SchemaGen.\n",
        "* `SchemaGen <<< StatisticsGen`\n",
        "\n",
        "> ExampleValidator.\n",
        "* `ExampleValidator <<< [StatisticsGen, SchemaGen]`\n",
        "\n",
        "> Transform.\n",
        "* perform feature engineering for both training and serving dataset.\n",
        "* These will run with under the hood by ApacheBeam.\n",
        "1. set constant module file. `data_constant.py`\n",
        "    * `%%writefile {data_constant.py}`.\n",
        "    * indicate `CATEGORICAL_FEATURES`<<< converted to indices.\n",
        "    * indicate `NUMERICAL_FEATURES` <<< continuous.\n",
        "    * indicate `BUCKET_FEATURES` <<< numerical that will be bucketized.\n",
        "    * indicate `FEATURE_BUCKET_COUNT` <<< dict of each bucket number.\n",
        "    * indicate `LABEL` that model will predict.\n",
        "2. set transform modeul file. `data_transform.py`.\n",
        "    * `%%writefile {data_transform.py}`.\n",
        "    * unpack all content from `data_constant.py`.\n",
        "    * preprocessing_fn:\n",
        "        - `NUMERICAL_FEATURE` scale_to_0_1.\n",
        "        - `BUCKET_FEATURE` bucketize as bucket count.\n",
        "        - `CATEGORICAL_FEATURE` convert into indices.\n",
        "        - `LABEL` convert label string into indices.\n",
        "3. Instantiate the Transform Component.\n",
        "    * `Transform <<< [ExampleGen, SchemaGen, data_transform.py]`.\n",
        "4. The Examine the output artificats:\n",
        "    * get uri from transformed_example\n",
        "    * get list of file in train_uri.\n",
        "    * create `TFRecordDataset` to read these files.\n",
        "    * use util function (own) get_record() to get samples of transform data.\n",
        "\n",
        "Important Libraries:\n",
        "* Tensorflow: framework.\n",
        "* tfx.components: all tfx for transformer pipeline.\n",
        "* tfx orchestration: interactive context.\n",
        "* google MessageToDict: Vocabulary Indication.\n",
        "* os: directory control.\n",
        "* pprint: Pretty Printer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***LAB7 - Feature Selection***\n",
        "\n",
        "***Objectives and Methodlogies:***\n",
        "* Picking sets of features that are most relevant to target variable.\n",
        "* Reducing model complexity.\n",
        "* Breast Cancer Dataset.\n",
        "- ***Filter Methods:*** \n",
        "    - correlation with target variable.\n",
        "    - correlation with other features.\n",
        "    - unvariate Selection with scikit-learn.\n",
        "- ***Wrapper Methods:***\n",
        "    - recursive feature elimination.\n",
        "    - sequential feature selector.\n",
        "- ***Embedded Methos:***\n",
        "    - feature importances.\n",
        "    - L1 regularization.\n",
        "\n",
        "> Import Libraries and Load Dataset:\n",
        "* `sklearn` modules for feature selection and model evaluation.\n",
        "* `matplotlib, seaborn` for visualization.\n",
        "* load breast cancer data via pandas df.\n",
        "\n",
        "> Data Cleaning:\n",
        "* remove unwanted features,including \"unnamed col, id\"\n",
        "* integer encode. change string to int for binary-classifier.\n",
        "\n",
        "> Function for model trianing and evaluation.\n",
        "- input (X,Y) >>> sklearn standardscaler\n",
        "- RandomforestClassifier >>> train with (x_train, y_train) >>> sklearn evaluates metrics (x_test, y_test)\n",
        "- construct dataframe to display as \"all features\".\n",
        "\n",
        "> Correlation Matrix.\n",
        "* corr() see Pearson correlation score on each features.\n",
        "\n",
        "> Filter Method.\n",
        "* rank a given set of features from statistical methods.\n",
        "\n",
        "    > Correlation with Target Variable.\n",
        "    * strongness of features correlated with dianosis (target var).\n",
        "    * RESULT: higher accuracy and F1 score.\n",
        "\n",
        "    > Correlation with Other Features.\n",
        "    * use for remove features that highly correlated with other features, to remove redundant features for simpler model.\n",
        "    * RESULT: less feature inputs, faster training, same accuracy and F1-score as strong feature performance.\n",
        "\n",
        "    > Unvariate Selection with Scikit-Learn.\n",
        "    * ANOVA F-values to select top 20 features.\n",
        "    * RESULT: same accuracy and F1-score with lower feature count.\n",
        "\n",
        "> Wrapper Methods.\n",
        "* Methods to measure effectiveness of subset of features.\n",
        "    > SequentialFeatureSelector.\n",
        "    * can be used for adding or reducing features with a k-fold coress validation to see the effectiveness of features. Re\n",
        "    > Recursive Feature Elinmination.\n",
        "    * backward eliminatino but use feature importance scores to prune features.\n",
        "    * RESULT: slightly drop performance.\n",
        "\n",
        "> Embedded Methods.\n",
        "* use power of machine learning brnaches type such as randomforest classifier to see feature importances.\n",
        "    > Feature Importances.\n",
        "    * after `SelectFromModel` the model can reduce featurecount base on its importances.\n",
        "    * RESULT: less feature count, same accuracy and F1-score as RFE\n",
        "    > L1 Regularaization Feature Selector.\n",
        "    * Lasso Regularization itroduce a penalty term to loss function.\n",
        "    * `SelectFromModel(LinearSVC(C=1, penalty='l1'))`\n",
        "    * RESULT: less accuracy and F1-score\n",
        "\n",
        "***Summarize:***\n",
        "* if you focus on F1-score select `Strong Features, Subset Features, and F-Test`. On the other hands, if all scores are acceptable, then use the smallest set of features.\n",
        "\n",
        "***Important Libraries:***\n",
        "* Tensorflow: framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***LAB8 - Feature Engineering (Assignment)***\n",
        "\n",
        "***Objectives and Methodlogies:***\n",
        "* ***TFX component*** to prepare features from Metro dataset.\n",
        "* ***InteractiveContext*** to run TFX components.\n",
        "* ***ExampleGen*** to split dataset.\n",
        "* ***StatsticsGen*** and ***SchemaGen***.\n",
        "* ***ExampleValidator***.\n",
        "* ***TFX Transformer*** component performed feature engineering.\n",
        "\n",
        "> Setup\n",
        "* Import and Define Paths.\n",
        "    - tfx omponents, tft_beam, google MessageToDict, tfx interactiveConetxt, tft metadata, \n",
        "    - tempfile, pprint\n",
        "    - _pipeline_root. _data_root, _data_filepath\n",
        "\n",
        "* Preview the Dataset.\n",
        "    - !head {_adta_filepath}\n",
        "\n",
        "* Create the InteractiveContext.\n",
        "    - InteractiveContext(pipeline_root)\n",
        "\n",
        "> Run TFX components interactively\n",
        "* ExampleGen\n",
        "    - `CsvExampleGen(_data_root)` <<< conntext.run()\n",
        "    - get artifact for training example and create ***TFRecordDataset*** to read these files.\n",
        "    - define function for get recorded data.\n",
        "\n",
        "* StatisticsGen\n",
        "    - `StatisticsGen(CsvExampleGen.outputs['examples'])` <<< context.run()\n",
        "    - context.show()\n",
        "\n",
        "* SchemaGen\n",
        "    - `SchemaGen(StatisticsGen.outputs['statistics'])` <<< context.run()\n",
        "    - context.show()\n",
        "\n",
        "* ExampleValdiator\n",
        "    - `ExampleValidator(Stats, Schema)` <<< context.run()\n",
        "    - context.show(['anomalies])\n",
        "\n",
        "* Transform\n",
        "    - %%writefile constants_module_file\n",
        "        + DENSE_FLOAT_FAETURE (z-score)\n",
        "        + BUCKET_FEATURE\n",
        "        + BUCKET_COUNT\n",
        "        + RANGE_FEATURE (0, 1)\n",
        "        + VOCAB_SITE\n",
        "        + OOV_SIZE\n",
        "        + VOCAB_FEATURE\n",
        "        + CATEGORICAL_FEATURE\n",
        "        + PREDICT_FEATURE (target)\n",
        "    - %%writefile transform_module_file\n",
        "        + unpack all contents from constant module.\n",
        "        + def preprocessing_fn:\n",
        "            - scale_to_z_score\n",
        "            - scale_to_0_1\n",
        "            - compute_and-apply_vocab\n",
        "            - bucketize\n",
        "            - do nothing for CATEGORICAL\n",
        "            - tf cast target to 1 and 0 if target more than mean\n",
        "    - test preprocessing_fn with `tft_beam`\n",
        "    - use MessageToDict to see if transformed_metadata.schema match SchemaGen\n",
        "    - Instantiate Transform Component.\n",
        "        + Transform(exampeGen, SchemaGen, transform_module_file)\n",
        "        + context.run()\n",
        "        + get graph_uri, train_uri, list files directory, and create `TFRecordDataset`\n",
        "\n",
        "***Important Libraries:***\n",
        "+ os: control directory.\n",
        "+ tensorflow: framework.\n",
        "+ tfx.components: Pipeline components.\n",
        "+ tft_beam: scalable transofrm pipeline.\n",
        "+ tfx.orchestration: InteractiveContext.\n",
        "+ tempfile: temp_dir for preprocessing pipeline testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LAB WEEK3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***LAB9 - Walkthrough of ML Metadata***\n",
        "* API for tracking of any progress made in ML projects, especially when running TFX pipelines. Each components automatically records information to metadata stores.\n",
        "* It allows to retrieve information such as name of trianing splits, location of inferred schema.\n",
        "\n",
        "Objectives and Methodologies:\n",
        "* ML Metadata will be used directly for recording and retrieving metadata independent from TFX pipeline ( without TFX components).\n",
        "* TFDV for creating schema.\n",
        "\n",
        "> Import Libraries and Download daaset.\n",
        "* import libraries and version checking for {tf, tfdv}.\n",
        "* use urllib and zip to download zip and extract files.\n",
        "\n",
        "> Define ML Metadata's Storage Database.\n",
        "* Instantiate a connection config by `metadata_store_pb2`.\n",
        "* set parent database (inthis exp use fake_database).\n",
        "* setup Metadata store <<< connecting_config.\n",
        "\n",
        "> ArtifactType and ExecutionTypes - setting up .\n",
        "* create ArtifactType for input dataset by setting up name, and properties.\n",
        "* create ArtifactType for Schema by setting up name, and properties.\n",
        "* `put_artifact_type` register both artifacts to meatadata store.\n",
        "* create ExecutionType for TFDV by setting up name, and properties.\n",
        "* `put_schema_type` register execution type to metadata store.\n",
        "* ***RETURN*** - `data_artifact_type_id`, `schema_artifact_type_id`, `dv_execution_type_id`. \n",
        "\n",
        "> Artifact and Execution Unit - generating input .\n",
        "* declare input artifact of dataset including \"path, id, names, split_name, version\"\n",
        "* `put_artifacts` register to metadata store.\n",
        "* declare input Execution of Data Validation run including \"id, state\".\n",
        "* `put_executions` register to metadata store.\n",
        "* ***RETURN*** - `data_artifact_id`, `dv_execution_id`\n",
        "\n",
        "> Register input event.\n",
        "* This event define relationship between \"Artifacts and Executions\".\n",
        "* declare input event, by data_artifact_id, dv_execution_id, DECLARE_INPUT.\n",
        "* `put_events` into metadata store.\n",
        "\n",
        "> Run the TDFV component.\n",
        "* infer schema by passing train_data, train_stats into `tfdv.infer_schema`\n",
        "* write schema text file <<< schema_file.\n",
        "* ***RETURN*** - `schema_file`.\n",
        "\n",
        "> Artifact Unit - generate output.\n",
        "* declare output artifact of type schema_artifact including \"shema_file, schema_artifact_type_id, version, name\".\n",
        "* `put_artifact` register to metadata store by schema_artifact.\n",
        "* ***RETURN*** - `schema_artifact_id`\n",
        "\n",
        "> Register output event.\n",
        "* This event record output artifact of particular execution unit.\n",
        "* declare output event, by schema_artifact_id, dv_execution_id, DECLARE_OUTPUT.\n",
        "* `put_events` register to metadata store.\n",
        "\n",
        "> Update the execution unit.\n",
        "* mark state of dv_execution as COMPLETE.\n",
        "* `put_executions` register to metadata store by dv_execution.\n",
        "\n",
        "> Setting up Context Types.\n",
        "* Context Unit group to artifacts and execution units.\n",
        "* create ConntextType by \"name, and properties\".\n",
        "* `put_context_type` register to meatadata store.\n",
        "***RETURN*** - `expt_context_type`.\n",
        "\n",
        "> Generating a Context Unit\n",
        "* generate context by \"name, and propertise\" linked type_id to expt_conetext_type.\n",
        "* ***RETURN*** - `expt_context`.\n",
        "\n",
        "> Generate Attribution and association relationships.\n",
        "* generate Attricution with \"schema_artifact_id, and expt_context_id\".\n",
        "* generate Association with \"dv_execution_id, and expt_context_id\".\n",
        "* `put_attributions_and_associations` register to metadata store.\n",
        "* ***RETURN*** - `expt_attribution`, `expt_association`.\n",
        "\n",
        "> Retrieving Information from the Metadata Stores.\n",
        "* Now you can track everything without seeing the code by retrieving metadata store informations.\n",
        "* example usages:\n",
        "    + get_artifact_type\n",
        "    + invest elements in list of get_artifact_type\n",
        "    + get_events_by_artifact_ids\n",
        "    + get_events_by_execution_ids\n",
        "    + get artifacts_by_id\n",
        "\n",
        "Important Libraries:\n",
        "* ml_metadata: metadata storage, and proto(instantiate units and types).\n",
        "* tensorflow: framework.\n",
        "* tfdv: data validation.\n",
        "* urlfile, zipfile: files control and zipping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***LAB10 - Iterative SChema***\n",
        "\n",
        "Objectives and Methodlogies:\n",
        "* Review how to update an infereed schema and save the result to the metadata store used by TFX.\n",
        "* Acessing the TFX metadtaa store and see track the lineage of an artifact.\n",
        "\n",
        "***Setup***\n",
        "> Import Libraries and Define Paths.\n",
        "* import tensorflow, tfx.components, tfdv.\n",
        "* import tfx. orchesteration for interactive context.\n",
        "* import google MessageToDict, schma_pb2\n",
        "* import os, pprint\n",
        "* define -> {pipeline_root, data_root, data_filepath}\n",
        "\n",
        "***Data Pipeline***\n",
        "> Create Interactive Context\n",
        "* `context` -> InteractiveConetxt(`pipeline_root`)\n",
        "\n",
        "> ExampleGen\n",
        "* `example_gen` -> CsvExampleGen(`data_root`)\n",
        "* context.run()\n",
        "\n",
        "> StatisticsGen\n",
        "* `statistics_gen` -> StatisticsGen(`example_gen.outputs`)\n",
        "* context.run()\n",
        "\n",
        "> SchemaGen\n",
        "* `schema_gen` -> SchemaGen(`statstics_gen.outputs`)\n",
        "* context.run()\n",
        "* context.show()\n",
        "\n",
        "> Curating Schema\n",
        "* `schema_uri` -> get Schema artifact uri.\n",
        "* `schema` -> get schema pbtxt file by tfdv.load_schema_text.\n",
        "* now we can make changes to schema by:\n",
        "    + `tfdv.set_domain(schema, domain_name, schema_pb2(detail here))`\n",
        "* tfdv.display_schema\n",
        "\n",
        "> Schema Environment\n",
        "* create schema env for {TRAINING, SERVING}\n",
        "* omit label from serving env -> not_in_env.append('SERVING')\n",
        "* declare path for update_schema -> piprline_root/updated_schema\n",
        "* create mkdir -p {...}\n",
        "* declare schema file -> updated_dir/schema.pbtxt\n",
        "* tfdv write_schema_text\n",
        "\n",
        "> ImporterNode\n",
        "* Use an ImporterNode to put curated schema to ML Metadata by create artifact from  tfx ImporterNode:\n",
        "    + `use_schema_importer` input: {instance_name, updated_schema_dir, artifact_type}\n",
        "* context.run(), show()\n",
        "\n",
        "> ExampleValidation\n",
        "* Instantiate ExampleValidator( statstics_gen.outputs, user_schema_importer.outputs )\n",
        "* context.run(), show()\n",
        "\n",
        "***Example with Metadata***\n",
        "* We can now tracking artifacts and relationships ieach component in pipeline.\n",
        "* Able to track the inputs and outputs even in hundred of training runs and parameter iterations.\n",
        "1. Import ml_metadata and utiliters from ml_metadata.proto\n",
        "2. get `connection_config` from context.\n",
        "3. Instantiate a MetadataStore instance with `conntection_config`\n",
        "4. get artifact types -> print out its names.\n",
        "* now we can do much things:\n",
        "    + get schema_list.\n",
        "    + get exampleaAnomalies and its detail by id.\n",
        "    + get events detail by execution_id (ex. from anomalies_id)\n",
        "    + filter INPUT type events to get event.artifact_id\n",
        "\n",
        "Important Libraries:\n",
        "* tensorflow: framework.\n",
        "* tfx.components: pipeline components.\n",
        "* tfx.orchestration: interactivecontext.\n",
        "* google MessageToDict: embbeded words.\n",
        "* tf schema_pb2: Curating schema.\n",
        "* ml_metadata: for tracking the recorded metadata store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ***LAB11 Datapipeline Components for Production ML (Assignment)***\n",
        "\n",
        "Objectives and Methodologies:\n",
        "* Data Ingestion, Data Validation, Data Transformation.\n",
        "* Build Data Pipeline by:\n",
        "    + performaing feature selection.\n",
        "    + Ingesting the dataset.\n",
        "    + Generating the statistics of the dataset.\n",
        "    + Creating a schema as per the domain knowledge.\n",
        "    + Creating schema environment.\n",
        "    + Visualizing the dataset anomalies.\n",
        "    + Preprocessing, transforming and engineering features.\n",
        "    + Tracking the provenance of data pipeline using ML Metadata.\n",
        "\n",
        "1. Imports\n",
        "* tensofrlow, tfx.components, tfdv, tft\n",
        "* tfx.orchestration\n",
        "* sklearn feature_selection\n",
        "* matplotlib, seaborn\n",
        "* utilities from tf, tf_metadata, google MessageToDict, tft_beam\n",
        "* os, pprint, pandas, tempfile\n",
        "* check version of tf, tfx, tfdv, tft\n",
        "\n",
        "2. Load Dataset\n",
        "* both quantitative, qualitative, and integer (labels).\n",
        "* declare `Data_DIR`, `TRAINING_DIR` -> mkdir, `TRAINING_DATA` (from TRAINING_DIR)\n",
        "* !wget -nc https:___ -P {TRAINNIG_DIR} -> download data.\n",
        "\n",
        "3. Feature Selection\n",
        "* pandas read to df.\n",
        "* head, df.dtypes for display example and data types.\n",
        "* df.copy for protext original data.\n",
        "* define {cat_cols, label_cols}\n",
        "* drop cat_cols and label_cols as df_num\n",
        "* set target label_cols as y\n",
        "* set input value as X from df_num.values\n",
        "\n",
        "    > Feature Selection\n",
        "    * univariate feature selection by SelectKBest(k=8).\n",
        "    * mkdir -p {TRAINING_DIR_FSLECT} , and define path\n",
        "    * get selected feature name. \n",
        "        + -> append it with label_cols, cat_cols as `df_select`\n",
        "        + write it to_csv to path TRAINING_DATA_SELECT\n",
        "        + head()\n",
        "\n",
        "4. Data Pipeline\n",
        "* TFX data pipeline for ingesting, validating, transforming.\n",
        "    > Setup the Interactive Context\n",
        "    * declare InteractiveContext(pipeline_root)\n",
        "\n",
        "    > ExampleGen\n",
        "    * `example_gen` -> CsvExampleGen(TRAINING_DIR_FSELECT)\n",
        "    * context.run()\n",
        "\n",
        "    > StatisticsGen\n",
        "    * statistics_gen = StatisticsGen(example_gen.outputs)\n",
        "    * context.run(), show()\n",
        "\n",
        "    > SchemaGen\n",
        "    * schema_gen = SchemaGen(statstics_gen.outputs)\n",
        "    * context.run(), show()\n",
        "\n",
        "    > Curating the SChema\n",
        "    * `schema` = get artifact schema_uri by schema_gen.outputs.\n",
        "    * tfdv.set_domain -> use schema_pb2.InDomain to set domain {name, min, max} based on `schema`.\n",
        "    * display_schema(`schema`).\n",
        "\n",
        "    > Schema Environments\n",
        "    + define serving data.\n",
        "        * declare paths for serving data. -> mkdir {SERING_DIR}\n",
        "        * read serving_data and drop label_cols.\n",
        "        * save to_csv and del serving_data var.\n",
        "    + define stats_options.\n",
        "        * declare StatsOptions to use the curated schema. by `tfdv.StatsOption`\n",
        "        * compute statistics of serving dataset. by `tfdv.generate_statistic_from_csv` -> {SERVING_DATA, stats_options}\n",
        "        * detect anamalies by `tfdv.validate_statistics` -> {serving_stats, schema}\n",
        "        * display -> label_cols missing.\n",
        "    + Define serving env.\n",
        "        * append TRAINING and SERVING env to schema.\n",
        "        * Remove label_cols from SERVING env.\n",
        "        * anomalies detection again with {env=SERVING}\n",
        "        * display -> no anomalies found.\n",
        "        * declare path for updated_schema. -> mkdir\n",
        "        * write_schema_text as `schema.pbtxt`\n",
        "        * check by load_schema_text as new_schema and display it.\n",
        "\n",
        "    > Generate new statistics using the updated schema\n",
        "    + ImporterNodeSchemaGen\n",
        "        * user_schema_importer -> ImporterSchemaGen(schema_file)\n",
        "        * context.run(), show()\n",
        "\n",
        "    + StatisticsGen with the new schema\n",
        "        * StatisticsGen(example_gen.outputs, StatsOption, user_schema_importer.outputs)\n",
        "        * context.run(), show()\n",
        "\n",
        "    > Check Anomalies\n",
        "    * ExampleValidator( statistics_gen.outputs, user_schema_importer.outputs )\n",
        "    * context.run(). show()\n",
        "\n",
        "    > Feaure Engineering\n",
        "    + %%writefile {constant_model.py}\n",
        "        * scale_minmax feature keys.\n",
        "        * scale_01 feature keys.\n",
        "        * scale_z feature keys.\n",
        "        * vocab feature keys.\n",
        "        * has_string feature keys.\n",
        "        * label key.\n",
        "\n",
        "    + Proprocessing function.\n",
        "        * %%writefile {transform.py}\n",
        "        * import tf, tft, constant_mode.py\n",
        "        * unpack all feature keys.\n",
        "        * def preprocessing_fn: -> feed inputs[feature] for feature in xxx__feature_key -> compute by tft components.\n",
        "        * RETURN feature_dict\n",
        "        * Test proprocessing_fn\n",
        "            + import testing_value\n",
        "            + load dataset, feature_spec to dataset_metadata.DatasetMetadata\n",
        "            + use tft_beam.Context with tempfile to pipe rae_data, raw_data_metadata to preprocessing_fn \n",
        "            + result var -> transformed_data, transformed_metadata\n",
        "            + Test transform_metadata's schema by MessageToDict. Should be matched.\n",
        "\n",
        "    + Transform\n",
        "        * Instatiate the Transform component by {example_gen.outputs, schema_gen, transform.py}\n",
        "        * context.run()\n",
        "        * inspect by:\n",
        "            +  getting uri, get list of files dir.\n",
        "            + create `TFRecordDataset` to read these list.\n",
        "            + use get_record utils. pprint()\n",
        "\n",
        "5. ML Metadata\n",
        "* import ml_metadata, store_pb2\n",
        "* get connection_config to context.\n",
        "* instantiate metadataStore instance with connection_config\n",
        "* decalre base dir for TFX artifacts by `metadata.sqlite`\n",
        "+ Accessing stored artifacts by 'store.___':\n",
        "    * get artifact types.\n",
        "    * -> display_types()\n",
        "    * get_artifacts_by_type.\n",
        "    * -> display_artifacts()\n",
        "    * To get latest TransformGraph artifact.\n",
        "    * -> get_artifacts_by_types('ExampleStatistics')[-1]\n",
        "    * -> display_properties()\n",
        "\n",
        "> Tracking artifacts.\n",
        "* example of how to build function to reutrn parent artifacts of given one to see artifacts that used to generate a TransformGraph instance.\n",
        "+ Get parent artifacts\n",
        "    * def get_parent_artifacts(store, artifact):\n",
        "        - get artifact_id\n",
        "        - get artifact_id_events\n",
        "        - get execution_id from events. -> event.type == OUTPUT\n",
        "        - get execution_id_events\n",
        "        - get parent_artifact_ids by execution_id_events -> event.type == INPUT\n",
        "        - RETURN -> get parent_artifact_list\n",
        "    * test:\n",
        "        - by get artifact instance from metadata store ('TransformGraph')[0]\n",
        "        - feed to get_parent_artifacts(store, artifact_instance)\n",
        "        -  display()\n",
        "\n",
        "Important Libraries:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Course 3 - Machine Learning Modeling Pipelines in Production"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neural Architecture Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameters Tuning: Searching for Best Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AutoML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AutoML Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Resource Management Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quantization and Pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## High-Performance Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### High-Performance Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Knowledge Distillation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Analysis (TFMA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Analysis Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Advanced Mode Analysis and Debugging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Continuous Evaluation and Monitoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpretability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explainable AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding Model Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Laboratories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***LAB12 - Keras Tuner and Trainer***\n",
        "\n",
        "**Objectives and Methodlogies:**\n",
        "* use TFX to create data pipeline including tfx components.\n",
        "* set transformation for tfx pipeline.\n",
        "* create Tuner and Trainer components for hyperparameter tuning and select best model.\n",
        "* save model and its artifact.\n",
        "\n",
        "**Steps and Requirements:**\n",
        "1. datasets astype float32 < proper for the classifier >.\n",
        "2. keras model < the classifier >.\n",
        "3. keras tuner < perform hypertuning >.\n",
        "    3.1 define model builder:\n",
        "        - initiate units in dense layer and choose optimal range of units.\n",
        "        - add dropout for robuestness.\n",
        "        - choose optimal learning-rate.\n",
        "        - set complie.\n",
        "4. perform tuning\n",
        "    - initiate tuner and set objective (accuracy), epochs, dir, name, early_stopping.\n",
        "\n",
        "**Libraries:**\n",
        "* pip\n",
        "* tensorflow\n",
        "* keras\n",
        "* tensorflow-estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***LAB13 - TFX Tuner and Trainer***\n",
        "\n",
        "**Objectives and Methodlogies:**\n",
        "* Hypterparameter Tuning within Tensorflow Extended (TFX).\n",
        "* Get best set of hypterparameters from Tuner component and feed into Trainer component.\n",
        "* after tuned hyperparameters, it can be reproduced by `ImporterNode`.\n",
        "\n",
        "**Steps and Requirements:**\n",
        "1. define `pipeline_root`, `data_root`, `tempdir`.\n",
        "2. define `tfds` if donwloaded via `tfds.load()`.\n",
        "3. initialize `InteractiveContext`.\n",
        "4. doing **TFX Pipeline**: ExmapleGen, StatisticsGen, SchemaGen, ExampleValidator.\n",
        "5. write `transform.py` < preprocessing data in each feature: name, img, label >.\n",
        "6. Tuner.\n",
        "    * write `tuner.py` < look for `tuner_fn()` >\n",
        "        - create `readder` and `batcher` function.\n",
        "        - create `model_builder(hp)` define initial values and optimal range of each hp.\n",
        "        - create `tuner_fn -> TunerFnResult` using KerasTner API. \n",
        "    * setup the Tuner component ( with trainer_pb2 ).\n",
        "7. Trainer\n",
        "    7.1 write `trainer.py` < look for `run_fn()` >\n",
        "        - create `reader` and `batcher` function.\n",
        "        - create `model_builder(hp)` passing tuned hp\n",
        "        - create `run_fn -> None` result in saved model tf.\n",
        "    7.2 setup the TRainer component ( with trainer_pb2 passing `tuner.output` ).\n",
        "8. run conetxt and print contents.\n",
        "\n",
        "**Libraries:**\n",
        "* pip\n",
        "* tfx\n",
        "* tensorflow\n",
        "* keras\n",
        "* tensorflow-estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***LAB14 - Manual Feature Engineering***\n",
        "\n",
        "**Objectives and Methodlogies:**\n",
        "* define model by feature columns.\n",
        "* use Lambda layers to perform feature engineering.\n",
        "* compare performance.\n",
        "\n",
        "**Steps and Requirements:**\n",
        "1. tf load csv dataset and split into features, labels.\n",
        "2. build keras classifier.\n",
        "3. train model, and visualize loss metrics of train and eval dataset.\n",
        "4. **Problem** with geo-spatial features\n",
        "    * define euclidean params and drop unncessary columns.\n",
        "    * define some scaling functions.\n",
        "    * build `transform` function with Lambda to pass columns into scaling and euclidean function.\n",
        "5. update model with constructor for `DenseFeatures`\n",
        "    * result in reduce inputs dims and we can visualize how ecah feature was transform by Lambda to be new scaled feature.\n",
        "6. train and visualize new performance.\n",
        "\n",
        "**Libraries:**\n",
        "* pip\n",
        "* Lambda\n",
        "* tensorflow\n",
        "* keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***LAB15 - Algorithmic Dimensionality Reduction***\n",
        "\n",
        "**Objectives and Methodlogies:**\n",
        "* PCA: unsupervised linear combinations relies on eigen vector with fast and easy implementation.\n",
        "* SVD: metrix decomposition not relies on eigen vector, fit for non square matrics.\n",
        "* NMF: can perform with non-negative features including topics and images by define n_vector_dim and n_topic to group the sample.\n",
        "\n",
        "**Libraries:**\n",
        "* pip\n",
        "* sklearn.decomposition.\n",
        "* tensorflow\n",
        "* keras\n",
        "* numpy, pandas, seaborn, matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***LAB16 - Quantization and Pruning***\n",
        "\n",
        "**Objectives and Methodlogies:**\n",
        "* reduced model size and latency ex. for edge computing and IOT devices by these techniques:\n",
        "    - **post-training quantization:** \n",
        "        - convert float to int to reduce model size and achieve faster computation.\n",
        "        - convert post training model ex. convert_tflite.\n",
        "        - loss accuracy.\n",
        "    - **quantization aware training:**\n",
        "        - insert fake quant modes in model training.\n",
        "        - longer training time, higher accuracy in post quantizing model than post-training method.\n",
        "    - **weight pruning:**\n",
        "        - zero out insignificant weights.\n",
        "        - quantize during model training with defined pruning schedule (sparisity rampup to epoch).\n",
        "        - finally strip pruning to remove wrapper of zero weighted nodes.\n",
        "        - same model size but 3x smaller after compress model. then can far more with post-training-pruning.\n",
        "\n",
        "**Libraries:**\n",
        "* tf_model_optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***LAB17 - Distributed Strategies with TF and Keras***\n",
        "\n",
        "**Objectives and Methodlogies:**\n",
        "* `tf.distribute.MultiworkerMirroredStrategy` is used for tf, keras for distributed strategies.\n",
        "* single-worker training.\n",
        "* simulate different machines.\n",
        "* multi-worker training.\n",
        "\n",
        "**Implementatino Steps:**\n",
        "1. [learning only] disable GPU to prevent error, [practical case] each worker in different machine.\n",
        "2. create `data_and_model.py` including train_dataset and model functions.\n",
        "3. load and train model on single-worker strategy.\n",
        "4. Multi-Worker Configuration\n",
        "    * `tf_config`\n",
        "        - `cluster`: define woker's ip(s)\n",
        "        - set task index to 0, set os env by json dump.\n",
        "    * create `main.py`\n",
        "        - import module file ( data_and_model.py ).\n",
        "        - load env `TF_CONFIG`, define strategy, batch size, load data, train in strategy manager [`with strategy.scope():`].\n",
        "    * lanuch 1st worker.\n",
        "        - use `bash` command to run `main.py &> job_0.log` and save logs.\n",
        "    * launch 2nd worker.\n",
        "        - set tf_config's index = 1, set os env by json dump.\n",
        "        - use `bash` command to run `main.py` and cat log to visualize results.\n",
        "\n",
        "**Libraries:**\n",
        "* `tf.distribute.MultiworkerMirroredStrategy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***LAB18 - Knowledge Distillation***\n",
        "\n",
        "**Objectives and Methodlogies:**\n",
        "* model compression technique `knowledge distillation` -> `student` model learn from `teacher`\n",
        "* Steps of implementation are:\n",
        "    - Define `Distiller` class for distillation procecss strategy.\n",
        "    - Train `teacher` complex model with regularization term.\n",
        "    - Train `student` smaller model without regularization by knowledge distillation.\n",
        "    - Train `student` without distillation.\n",
        "    - Compare these model performance.\n",
        "* result: `student` training with knowledge distillation out perform trainnig from scratch in almost epochs by learning the regulatization from `teacher` model.\n",
        "\n",
        "**Implementatino Steps:**\n",
        "1.  Import dataset. Splitting to train, test, eval data.\n",
        "2. Create `Distillation` class by `Distillation(keras,Model)`:\n",
        "    * __init__: `teacher`, `student`\n",
        "    * __complie__: use when calling model.complie()\n",
        "        - super to Distiallation Keras,\n",
        "        - complie with optimizer, metrics.\n",
        "        - add {`student`_loss_fn, distillation_loss_fn, alpha, temperature}\n",
        "    * __train_step__: use when calling model.fit()\n",
        "        - data < have to be tuple(features, labels) >\n",
        "        - get `teacher`'s loss\n",
        "        - get `student`'s loss and tape its Gradient, then compute total loss with distillation's loss(=ratio of `teacher` loss and `student` loss to temperature by softmax) and alpha(=weighting factors).\n",
        "        - calculate `student` gradient from tape, then update `student`'s train_vars.\n",
        "        - print metrics and results.\n",
        "    * __test_step__: use when calling model.evaluate()\n",
        "        - `student` prediction evaluation with set training=False.\n",
        "        - print and update complie_metrics state.\n",
        "3. Create `teacher` model and `student` model ( big and smaller model about 12times smaller in train_vars).\n",
        "    * last layer need no softmax activation because raw logits needed for knowledge distillation.\n",
        "    * `student` model no need of regularization ( dropout ), it will be learn from `teacher` distillation.\n",
        "4. Train `teacher` model.\n",
        "5. Train `student` model for baseline -> set as ``student`_scratch`.\n",
        "6. Create `Distillation` instance with `student` and `teacher` model:\n",
        "    * complie distillation model with arguments:\n",
        "        ```python\n",
        "        distiller.compile(\n",
        "            student_loss_fn <- SparseCategoricalCrossentropy(from_logits=True),\n",
        "            optimizer <- Adam(),\n",
        "            metrics <- SparseCategoricalAccuracy()],\n",
        "            distillation_loss_fn <- KLDivergence(),\n",
        "            alpha=0.05,\n",
        "            temperature=5,\n",
        "        )\n",
        "        ```\n",
        "    * fit distillation and collect to distillation_history.\n",
        "7. compare model performances.\n",
        "\n",
        "**Libraries:**\n",
        "* tensorflow\n",
        "* keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***LAB19 - TF Model Analysis***\n",
        "\n",
        "**Objectives and Methodlogies:**\n",
        "* \n",
        "\n",
        "**Implementatino Steps:**\n",
        "1. \n",
        "\n",
        "**Libraries:**\n",
        "* tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Course 4 - Deploying Machine Learning Models in Production"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Serving Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Introduction to Model Serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Serving Infrastructure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensorflow Serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Serving Patterns and Infrastructure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Serving Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scaling Infrastructure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Online Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch Inference Scenarios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch Processing with ETL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Management and Delivery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ML Experience Management and Workflow Automation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MLOPs Methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Management and Deployment Infrastructure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Monitoring and Logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Monitoring and Logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Decay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GDPR and Privacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ..."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
